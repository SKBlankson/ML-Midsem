{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59123fba-dc16-42a8-bace-5f280faeb1f2",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3337ec41-cadc-473f-8ec3-078abe061747",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T20:48:41.974957Z",
     "start_time": "2024-03-14T20:48:34.913079Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from d2l import torch as d2l\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde007e-c771-4470-bc89-1356e6da3984",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbcab07-a49b-40f2-8f31-79b19225bd4a",
   "metadata": {},
   "source": [
    "Here, we load the training set into a pandas dataframe and print the first 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d542e9bb-b349-4e00-9624-d221568c2c13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T20:49:02.299706Z",
     "start_time": "2024-03-14T20:49:00.395700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4        56  Assignment:  Visualization Reflection  Submitt...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, False, False, True, F...   \n",
       "1  [True, False, False, True, True, False, False,...   \n",
       "2  [True, False, False, True, True, False, False,...   \n",
       "3  [True, True, True, False, False, True, False, ...   \n",
       "4  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                              labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
       "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
       "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_data = pd.read_json('train.json')\n",
    "kaggle_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03480b2-eba9-45bc-8a89-83f593387df3",
   "metadata": {},
   "source": [
    "# Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d53cc6e-1ec5-40e2-97e1-751041da2741",
   "metadata": {},
   "source": [
    "In this section, the kaggle dataset is split into train and test variables.\n",
    "The train set contains the first 90% of the data (6126 examples)\n",
    "The test set contains the last 10% of the data (681 examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0804f898-7fd8-4784-b1bf-3c3fed56351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the first 90% of the data as the train set\n",
    "test_size = round(len(kaggle_data)*0.1) \n",
    "train_size = len(kaggle_data) - test_size\n",
    "\n",
    "# train_set, test_set = train_test_split(kaggle_data, test_size=len(kaggle_data)-train_size, random_state = False)\n",
    "train_set = kaggle_data.iloc[:train_size]\n",
    "test_set = kaggle_data.iloc[train_size:]\n",
    "\n",
    "# train_set\n",
    "test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973717a1-e503-4027-bc14-3268770ae692",
   "metadata": {},
   "source": [
    "### Visually inspect the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85bcffbe-20c5-4294-b89a-0b7f8509f801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4        56  Assignment:  Visualization Reflection  Submitt...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, False, False, True, F...   \n",
       "1  [True, False, False, True, True, False, False,...   \n",
       "2  [True, False, False, True, True, False, False,...   \n",
       "3  [True, True, True, False, False, True, False, ...   \n",
       "4  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                              labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
       "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
       "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the train set\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca453a5a-e007-40b2-ad79-be590bd033c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>21208</td>\n",
       "      <td>Learning Launch\\n\\nChallenge  I am a UX/UI Lea...</td>\n",
       "      <td>[Learning, Launch, \\n\\n, Challenge,  , I, am, ...</td>\n",
       "      <td>[True, False, False, True, False, True, True, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>21209</td>\n",
       "      <td>Reflection – Mind Mapping\\n\\nChallenge\\n\\nI am...</td>\n",
       "      <td>[Reflection, –, Mind, Mapping, \\n\\n, Challenge...</td>\n",
       "      <td>[True, True, True, False, False, False, False,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>21211</td>\n",
       "      <td>Example Reflection - Mind Mapping\\n\\nChallenge...</td>\n",
       "      <td>[Example, Reflection, -, Mind, Mapping, \\n\\n, ...</td>\n",
       "      <td>[True, True, True, True, False, False, True, T...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6129</th>\n",
       "      <td>21213</td>\n",
       "      <td>Company General Use\\n\\nElements:\\n\\n1. Challen...</td>\n",
       "      <td>[Company, General, Use, \\n\\n, Elements, :, \\n\\...</td>\n",
       "      <td>[True, True, False, False, False, False, False...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6130</th>\n",
       "      <td>21215</td>\n",
       "      <td>1 | P a g e\\n\\nExample Reflection – Visualizat...</td>\n",
       "      <td>[1, |, P, a, g, e, \\n\\n, Example, Reflection, ...</td>\n",
       "      <td>[True, True, True, True, True, False, False, T...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      document                                          full_text  \\\n",
       "6126     21208  Learning Launch\\n\\nChallenge  I am a UX/UI Lea...   \n",
       "6127     21209  Reflection – Mind Mapping\\n\\nChallenge\\n\\nI am...   \n",
       "6128     21211  Example Reflection - Mind Mapping\\n\\nChallenge...   \n",
       "6129     21213  Company General Use\\n\\nElements:\\n\\n1. Challen...   \n",
       "6130     21215  1 | P a g e\\n\\nExample Reflection – Visualizat...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "6126  [Learning, Launch, \\n\\n, Challenge,  , I, am, ...   \n",
       "6127  [Reflection, –, Mind, Mapping, \\n\\n, Challenge...   \n",
       "6128  [Example, Reflection, -, Mind, Mapping, \\n\\n, ...   \n",
       "6129  [Company, General, Use, \\n\\n, Elements, :, \\n\\...   \n",
       "6130  [1, |, P, a, g, e, \\n\\n, Example, Reflection, ...   \n",
       "\n",
       "                                    trailing_whitespace  \\\n",
       "6126  [True, False, False, True, False, True, True, ...   \n",
       "6127  [True, True, True, False, False, False, False,...   \n",
       "6128  [True, True, True, True, False, False, True, T...   \n",
       "6129  [True, True, False, False, False, False, False...   \n",
       "6130  [True, True, True, True, True, False, False, T...   \n",
       "\n",
       "                                                 labels  \n",
       "6126  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6127  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6128  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6129  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6130  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the test set\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee40e71-057b-4e16-9e56-fe44e87aa1f5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Extract labels and count them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3353149-3cef-4d2d-a25a-51261453f14f",
   "metadata": {},
   "source": [
    "The Most Frequent Count (MFC) assigns the most common class in a dataset as the prediction for every example.\n",
    "As such, we need to count the frequency of every class/label in the dataset. \n",
    "\n",
    "We used a dictionary to store the counts of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b427501d-3516-48ac-adee-9e104a383ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels to a variable\n",
    "labels = kaggle_data['labels']\n",
    "\n",
    "# Initialize a dictionary to count the labels\n",
    "count = dict()\n",
    "\n",
    "# Loop through labels and count them\n",
    "for entry in labels:\n",
    "    for label in entry:\n",
    "        if label not in count:\n",
    "            count[label]=1\n",
    "        else:\n",
    "            count[label]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399df505-48dd-4997-b340-3acb3c0a7416",
   "metadata": {},
   "source": [
    "# Sort labels in descending order and print the 2 most frequent classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42feee0c-efa7-4f2d-b617-2457d96f425b",
   "metadata": {},
   "source": [
    "The dictionary stores its entries in the order that they are added. \n",
    "As such, we need to sort the entries \n",
    "of the dictionary to get the first and second most frequent classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "025e75f3-63a0-4c7d-97b9-e278498c2172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-URL_PERSONAL', 'I-ID_NUM', 'B-STREET_ADDRESS', 'B-USERNAME', 'B-PHONE_NUM', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'B-EMAIL', 'B-ID_NUM', 'B-URL_PERSONAL', 'I-NAME_STUDENT', 'B-NAME_STUDENT', 'O']\n",
      "O\n",
      "B-NAME_STUDENT\n"
     ]
    }
   ],
   "source": [
    "# Sort the labels in descending order\n",
    "sorted_counts = sorted(count, key=count.get)\n",
    "sorted_counts\n",
    "\n",
    "# Get the most frequent class\n",
    "most_frequent = sorted_counts[-1]\n",
    "\n",
    "# Get the second most frequent class\n",
    "second_frequent = sorted_counts[-2]\n",
    "\n",
    "print(sorted_counts)\n",
    "print(most_frequent)\n",
    "print(second_frequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5679f-e5a3-4df7-9256-29ffb4956aee",
   "metadata": {},
   "source": [
    "# Define model to predict most frequent class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622f4cf-b67e-4fc7-b9cb-eb0c5a3b7dab",
   "metadata": {},
   "source": [
    "Here we define our MFC model. It takes 1 arguments: a dataframe containing the train dataset. The model returns 2 CSVs submissions-mfc.csv and evaluations-mfc.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18bfde5c-8732-4b74-8c0e-710c4a18eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFC(test_set, frequency):\n",
    "    \"\"\" A model that predicts the second most frequent\n",
    "    classification in the dataset for each example\n",
    "    @params test_set A pandas dataframe containing the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize arrays to store evaluations and predictions\n",
    "    submission_predictions = []\n",
    "    evaluations = []\n",
    "    \n",
    "    # Make predictions on the test values\n",
    "    count = 0\n",
    "    for index, row in test_set.iterrows():\n",
    "        for i in range(len(row['tokens'])):\n",
    "            if count > -1:\n",
    "                # Initialize arrays that will be wrriten to the files\n",
    "                prediction = [-1 , -1, -1, -1]\n",
    "                evaluation = [-1]\n",
    "\n",
    "                # if row['labels'][i] != 'O':\n",
    "                #     print('<>')\n",
    "                \n",
    "                # Assign values to prediction and evaluation arrays \n",
    "                prediction[0] = count # assign row id\n",
    "                prediction[1] = row['document']\n",
    "                prediction[2] = i # assign token number\n",
    "                if frequency == 'mfc':\n",
    "                    prediction[3] = most_frequent # assign prediction\n",
    "                elif frequency == 'nmfc': \n",
    "                    prediction[3] = second_frequent # assign prediction\n",
    "                evaluation[0] = row['labels'][i]\n",
    "\n",
    "\n",
    "                submission_predictions.append(prediction)\n",
    "                evaluations.append(evaluation)\n",
    "                count+=1\n",
    "            else:\n",
    "                break  \n",
    "    print('Predictions complete')\n",
    "\n",
    "\n",
    "  # Initialize file writers for submissions.csv and evaluations.csv\n",
    "    with open(f\"submissions-{frequency}.csv\",'w',newline = '') as f:\n",
    "        with open(f\"evaluation-{frequency}.csv\",'w',newline = '') as e:\n",
    "        # Write column headings to files\n",
    "            headings = ['row_id', 'document', 'token', 'label']\n",
    "            submission_writer = csv.writer(f)\n",
    "            eval_writer = csv.writer(e)\n",
    "            \n",
    "            submission_writer.writerow(headings)\n",
    "            eval_writer.writerow(headings)  \n",
    "            \n",
    "             # Write the predictions to the files\n",
    "            for i in range(len(submission_predictions)):\n",
    "                submission_writer.writerow(submission_predictions[i])\n",
    "                eval_writer.writerow(submission_predictions[i][0:3] + evaluations[i])\n",
    "            \n",
    "    print(f\"Files written to submissions-{frequency}.csv & evaluation-{frequency}.csv\")\n",
    "    return                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc27f9fc-5ca6-4444-9d29-a0f1f0a8b2bf",
   "metadata": {},
   "source": [
    "# Perform predictions using most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16a20c34-4d3a-43c9-a155-680e37ab3837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions complete\n",
      "Files written to submissions-mfc.csv & evaluation-mfc.csv\n"
     ]
    }
   ],
   "source": [
    "MFC(test_set,'mfc')      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f428d9-39be-4975-b3ca-524ea353b77a",
   "metadata": {},
   "source": [
    "# Perform predictions using the second most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d979da54-d501-4f31-8577-20c717ff7421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions complete\n",
      "Files written to submissions-nmfc.csv & evaluation-nmfc.csv\n"
     ]
    }
   ],
   "source": [
    "MFC(test_set,'nmfc')      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101efd1-a79b-463e-a981-e5d9fabad012",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca3064-c86a-407a-9ffb-050eb6cd073a",
   "metadata": {},
   "source": [
    "A confusion matrix is a helpful tool when calculating some evaluation statistics like precision and recall. The confusion matrix shows the true negative, true positive, false negative & false positives for each class in the predictions.\n",
    "\n",
    "Below, we define a function that generates the confusion matrix for the predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "969776cb-b056-4504-b977-eaf1df939b26",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 33\u001b[0m\n\u001b[0;32m     29\u001b[0m     matrix\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfusion_matrix.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m matrix\n\u001b[1;32m---> 33\u001b[0m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubmissions-mfc.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevaluation-mfc.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 24\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(predictions_csv, evaluations_csv)\u001b[0m\n\u001b[0;32m     22\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m evaluations\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predicted_label \u001b[38;5;241m==\u001b[39m ground_truth:\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     matrix[ground_truth][predicted_label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ML_Labs\\lib\\site-packages\\pandas\\core\\series.py:1149\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1147\u001b[0m check_dict_or_set_indexers(key)\n\u001b[0;32m   1148\u001b[0m key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1149\u001b[0m cacher_needs_updating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_is_chained_assignment_possible\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mEllipsis\u001b[39m:\n\u001b[0;32m   1152\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ML_Labs\\lib\\site-packages\\pandas\\core\\series.py:1333\u001b[0m, in \u001b[0;36mSeries._check_is_chained_assignment_possible\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_view \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_cached:\n\u001b[0;32m   1332\u001b[0m     ref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cacher()\n\u001b[1;32m-> 1333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ref \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_mixed_type\u001b[49m:\n\u001b[0;32m   1334\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_setitem_copy(t\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreferent\u001b[39m\u001b[38;5;124m\"\u001b[39m, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ML_Labs\\lib\\site-packages\\pandas\\core\\generic.py:6093\u001b[0m, in \u001b[0;36mNDFrame._is_mixed_type\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   6088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39many_extension_types:\n\u001b[0;32m   6089\u001b[0m     \u001b[38;5;66;03m# Even if they have the same dtype, we can't consolidate them,\u001b[39;00m\n\u001b[0;32m   6090\u001b[0m     \u001b[38;5;66;03m#  so we pretend this is \"mixed'\"\u001b[39;00m\n\u001b[0;32m   6091\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 6093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnunique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ML_Labs\\lib\\site-packages\\pandas\\core\\base.py:1068\u001b[0m, in \u001b[0;36mIndexOpsMixin.nunique\u001b[1;34m(self, dropna)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnunique\u001b[39m(\u001b[38;5;28mself\u001b[39m, dropna: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;124;03m    Return number of unique elements in the object.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;124;03m    4\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1068\u001b[0m     uniqs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dropna:\n\u001b[0;32m   1070\u001b[0m         uniqs \u001b[38;5;241m=\u001b[39m remove_na_arraylike(uniqs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ML_Labs\\lib\\site-packages\\pandas\\core\\series.py:2194\u001b[0m, in \u001b[0;36mSeries.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:  \u001b[38;5;66;03m# pylint: disable=useless-parent-delegation\u001b[39;00m\n\u001b[0;32m   2132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2133\u001b[0m \u001b[38;5;124;03m    Return unique values of Series object.\u001b[39;00m\n\u001b[0;32m   2134\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2192\u001b[0m \u001b[38;5;124;03m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[0;32m   2193\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ML_Labs\\lib\\site-packages\\pandas\\core\\base.py:1030\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1028\u001b[0m     result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1030\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ML_Labs\\lib\\site-packages\\pandas\\core\\algorithms.py:390\u001b[0m, in \u001b[0;36munique\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(values):\n\u001b[0;32m    297\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;124;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ML_Labs\\lib\\site-packages\\pandas\\core\\algorithms.py:429\u001b[0m, in \u001b[0;36munique_with_mask\u001b[1;34m(values, mask)\u001b[0m\n\u001b[0;32m    427\u001b[0m table \u001b[38;5;241m=\u001b[39m hashtable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 429\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def confusion_matrix(predictions_csv, evaluations_csv):\n",
    "    # Read predictions and evaluations as dataframes\n",
    "    predictions = pd.read_csv(predictions_csv)\n",
    "    evaluations = pd.read_csv(evaluations_csv)\n",
    "\n",
    "    # Initialize a dataframe to store the matrix\n",
    "          \n",
    "    # Specify heading names for columns and rows\n",
    "    headings =['I-URL_PERSONAL', 'I-ID_NUM', 'B-STREET_ADDRESS', \n",
    "             'B-USERNAME', 'B-PHONE_NUM', 'I-PHONE_NUM', 'I-STREET_ADDRESS',\n",
    "             'B-EMAIL', 'B-ID_NUM', 'B-URL_PERSONAL', 'I-NAME_STUDENT', 'B-NAME_STUDENT', 'O']\n",
    "\n",
    "    # Create an empty DataFrame with specified column and row n\n",
    "    matrix = pd.DataFrame(columns=headings, index= headings)\n",
    "\n",
    "    # Fill DataFrame with zeros\n",
    "    matrix = matrix.fillna(0)\n",
    "\n",
    "    # Count true and false positives for each class\n",
    "    for i in range(len(predictions)):\n",
    "        predicted_label = predictions.iloc[i]['label'] \n",
    "        ground_truth = evaluations.iloc[i]['label']\n",
    "        if predicted_label == ground_truth:\n",
    "            matrix[ground_truth][ground_truth] +=1\n",
    "        else:\n",
    "            matrix[ground_truth][predicted_label] +=1\n",
    "\n",
    "    # Write matrix to csv\n",
    "    matrix.to_csv('confusion_matrix.csv', index=True)\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "confusion_matrix('submissions-mfc.csv','evaluation-mfc.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f84732-26e9-4b98-b7ec-38614301be9b",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755fa53a-091b-4c3c-9bc6-c4ed483654c7",
   "metadata": {},
   "source": [
    "From our research, we determined that there are 2 methods for calculating Precision in multi-class scenarios: Macro Averaging and Micro Averaging.\n",
    "We decided to go with a Macro averaging approach because it assigns equal weights to each class. Micro averaging on the other hand, assigns equal weight to each prediction. Assigning equal weight to each prediction means that the overall precision is influenced greatly by datasets with dominant classes. In other words, micro averaging does not really illustrate the models ability to predict less prevalent classes. \n",
    "\n",
    "As such, we went with macro averaging since it gives each class equal importance and thus illustrates the models ability to predict classes that are not so frequent in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56941dd0-ae9c-4720-85f3-dd4e3fd8d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision(confusion_matrix):\n",
    "\n",
    "     # Read the confusion matrix as a df\n",
    "    matrix = pd.read_csv(confusion_matrix)\n",
    "    headings = matrix['Unnamed: 0']\n",
    "    print(headings)\n",
    "    # matrix.index = matrix['Unnamed: 0']\n",
    "    matrix.drop('Unnamed: 0')\n",
    "    print(matrix)\n",
    "    \n",
    "\n",
    "    # # Initiailize counters for true and false positives\n",
    "    # true_positives = 0\n",
    "    # false_positives = 0\n",
    "    \n",
    "    \n",
    "    # # Calculate true positives and false positives\n",
    "    # for i in range(len(predictions)):\n",
    "    #     if(predictions.iloc[i]['label'] == evaluations.iloc[i]['label']):\n",
    "    #         true_positives+=1\n",
    "    #     elif(predictions.iloc[i]['label'] \n",
    "    \n",
    "        \n",
    "Precision('confusion_matrix.csv')                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad21125-9a32-4905-82cc-9196ba471210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "050bcca5-d23a-44b5-aa7e-446bab4f456a",
   "metadata": {},
   "source": [
    "# b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
